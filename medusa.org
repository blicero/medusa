# -*- mode: org; fill-column: 78; -*-
# Time-stamp: <2025-06-05 19:34:35 krylon>
#
#+TAGS: internals(i) ui(u) bug(b) feature(f)
#+TAGS: database(d) design(e), meditation(m)
#+TAGS: optimize(o) refactor(r) cleanup(c)
#+TODO: TODO(t)  RESEARCH(r) IMPLEMENT(i) TEST(e) | DONE(d) FAILED(f) CANCELLED(c)
#+TODO: MEDITATE(m) PLANNING(p) | SUSPENDED(s)
#+PRIORITIES: A G D

* Medusa [18/19]
  :PROPERTIES:
  :COOKIE_DATA: todo recursive
  :VISIBILITY: children
  :END:
  An application to gather various metrics on hosts (e.g. CPU frequency,
  temperature, utilization, system load) and hopefully make pretty graphs out
  of that data.
** Clocktable
   #+BEGIN: clocktable :scope file :maxlevel 255 :emphasize t
   #+CAPTION: Clock summary at [2025-06-05 Do 19:31]
   | Headline                                  | Time      |            |          |          |       |      |
   |-------------------------------------------+-----------+------------+----------+----------+-------+------|
   | *Total time*                              | *4d 0:02* |            |          |          |       |      |
   |-------------------------------------------+-----------+------------+----------+----------+-------+------|
   | *Medusa [18/19]*                          | *4d 0:02* |            |          |          |       |      |
   | \_  /Features [1/1]/                      |           | /4:33/     |          |          |       |      |
   | \_    Intermittent connectivity [0/0]     |           |            |     4:33 |          |       |      |
   | \_  /Components [16/17]/                  |           | /3d 18:37/ |          |          |       |      |
   | \_    Main [0/0]                          |           |            |     0:40 |          |       |      |
   | \_    Probes [4/4]                        |           |            |    14:43 |          |       |      |
   | \_      Free disk space ?                 |           |            |          |     1:47 |       |      |
   | \_      Conditional imports               |           |            |          |     1:09 |       |      |
   | \_      Sensors [1/1]                     |           |            |          |     6:33 |       |      |
   | \_        FreeBSD                         |           |            |          |          |  1:35 |      |
   | \_    Model [0/0]                         |           |            |     2:17 |          |       |      |
   | \_    Database [2/2]                      |           |            |     1:45 |          |       |      |
   | \_      Exception handling                |           |            |          |     0:09 |       |      |
   | \_      Pool                              |           |            |          |     0:28 |       |      |
   | \_    Server [8/9]                        |           |            | 2d 14:24 |          |       |      |
   | \_      Web Interface [3/3]               |           |            |          | 1d 11:47 |       |      |
   | \_        Probe Graphs                    |           |            |          |          |  7:54 |      |
   | \_        Graphs [1/1]                    |           |            |          |          | 20:09 |      |
   | \_          Labels on Y-axis              |           |            |          |          |       | 0:25 |
   | \_      Error Handling [0/0]              |           |            |          |     0:58 |       |      |
   | \_      Protocol                          |           |            |          |    16:52 |       |      |
   | \_        Handle Agent HTTP communication |           |            |          |          |  0:49 |      |
   | \_        In a pickle                     |           |            |          |          |  1:51 |      |
   | \_    Agent [2/2]                         |           |            |     8:48 |          |       |      |
   | \_      HTTP FTW                          |           |            |          |     8:48 |       |      |
   | \_  /Bugs [1/1]/                          |           | /0:52/     |          |          |       |      |
   | \_    Error deserializing report data     |           |            |     0:38 |          |       |      |
   #+END:
** Features [1/1]
   :PROPERTIES:
   :COOKIE_DATA: todo recursive
   :VISIBILITY: children
   :END:
*** DONE Intermittent connectivity [0/0]
    CLOSED: [2025-06-02 Mo 19:46]
    :LOGBOOK:
    CLOCK: [2025-06-04 Mi 14:12]--[2025-06-04 Mi 15:35] =>  1:23
    CLOCK: [2025-06-02 Mo 18:49]--[2025-06-02 Mo 19:46] =>  0:57
    CLOCK: [2025-06-02 Mo 18:43]--[2025-06-02 Mo 18:45] =>  0:02
    CLOCK: [2025-05-19 Mo 17:21]--[2025-05-19 Mo 17:57] =>  0:36
    CLOCK: [2025-05-18 So 17:52]--[2025-05-18 So 18:18] =>  0:26
    CLOCK: [2025-05-17 Sa 21:46]--[2025-05-17 Sa 22:55] =>  1:09
    :END:
    I need to handle loss of connection, on both sides. I am also unsure if I
    notice on the server side when an Agent connection is gone.

    [2025-06-02 Mo 18:42]
    After switching the communication between Agent and Server to HTTP, I want
    to separate the collection of data in the Agent from submitting it to the
    Server.
** Components [16/17]
   :PROPERTIES:
   :COOKIE_DATA: todo recursive
   :VISIBILITY: children
   :END:
*** Main [0/0]
    :LOGBOOK:
    CLOCK: [2025-05-07 Mi 19:23]--[2025-05-07 Mi 20:03] =>  0:40
    :END:
    The entry point, where it all begins.
*** Probes [4/4]
    :PROPERTIES:
    :COOKIE_DATA: todo recursive
    :VISIBILITY: children
    :END:
    :LOGBOOK:
    CLOCK: [2025-05-10 Sa 16:37]--[2025-05-10 Sa 18:37] =>  2:00
    CLOCK: [2025-05-10 Sa 15:50]--[2025-05-10 Sa 16:33] =>  0:43
    CLOCK: [2024-01-26 Fr 15:00]--[2024-01-26 Fr 16:39] =>  1:39
    CLOCK: [2024-01-25 Do 17:58]--[2024-01-25 Do 18:50] =>  0:52
    :END:
**** DONE Free disk space ?
     CLOSED: [2025-05-27 Di 14:47]
     :LOGBOOK:
     CLOCK: [2025-05-13 Di 14:35]--[2025-05-13 Di 15:05] =>  0:30
     CLOCK: [2025-05-12 Mo 20:57]--[2025-05-12 Mo 22:14] =>  1:17
     :END:
**** DONE Conditional imports
     CLOSED: [2025-05-10 Sa 16:33]
     :LOGBOOK:
     CLOCK: [2025-05-09 Fr 17:20]--[2025-05-09 Fr 18:29] =>  1:09
     :END:
     I want to make the imports of the various probes conditional to keep the
     dependencies low.
     Also, I want to make the set of Probes an Agent runs configurable.
**** DONE Sensors [1/1]
     CLOSED: [2025-05-27 Di 14:47]
     :LOGBOOK:
     CLOCK: [2025-05-26 Mo 17:10]--[2025-05-26 Mo 17:11] =>  0:01
     CLOCK: [2025-05-20 Di 18:30]--[2025-05-20 Di 18:46] =>  0:16
     CLOCK: [2025-05-20 Di 14:41]--[2025-05-20 Di 15:26] =>  0:45
     CLOCK: [2025-05-19 Mo 20:34]--[2025-05-19 Mo 22:20] =>  1:46
     CLOCK: [2025-05-12 Mo 19:10]--[2025-05-12 Mo 20:57] =>  1:47
     CLOCK: [2025-05-12 Mo 18:12]--[2025-05-12 Mo 18:35] =>  0:23
     :END:
***** DONE FreeBSD
      CLOSED: [2025-05-27 Di 14:47]
      :LOGBOOK:
      CLOCK: [2025-05-26 Mo 17:11]--[2025-05-26 Mo 18:46] =>  1:35
      :END:
      On the one system I have FreeBSD running on bare metal, the only way I
      discovered to get sensor data is ipmitool.
*** Model [0/0]
    :PROPERTIES:
    :COOKIE_DATA: todo recursive
    :VISIBILITY: children
    :END:
    :LOGBOOK:
    CLOCK: [2025-04-22 Di 18:17]--[2025-04-22 Di 18:51] =>  0:34
    CLOCK: [2025-04-21 Mo 13:31]--[2025-04-21 Mo 15:14] =>  1:43
    :END:
*** Database [2/2]
    :PROPERTIES:
    :COOKIE_DATA: todo recursive
    :VISIBILITY: children
    :END:
    :LOGBOOK:
    CLOCK: [2025-04-22 Di 18:51]--[2025-04-22 Di 19:04] =>  0:13
    CLOCK: [2025-04-22 Di 18:17]--[2025-04-22 Di 18:17] =>  0:00
    CLOCK: [2025-04-22 Di 14:23]--[2025-04-22 Di 15:18] =>  0:55
    :END:
**** DONE Exception handling
     CLOSED: [2025-05-05 Mo 17:57]
     :LOGBOOK:
     CLOCK: [2025-05-05 Mo 17:48]--[2025-05-05 Mo 17:57] =>  0:09
     :END:
**** DONE Pool
     CLOSED: [2025-04-29 Di 20:40]
     :LOGBOOK:
     CLOCK: [2025-04-24 Do 18:43]--[2025-04-24 Do 19:11] =>  0:28
     :END:
     I want a connection pool, similar to what I created in Go.
     And I want it to be a context manager, so I can say something like
     #+BEGIN_SRC Python
       with db_pool.get() as db:
           db.do_something(blah)
     #+END_SRC
     such that the the database instance will be returned to the pool on exit
     from the block.
     ...
     [2025-04-24 Do 19:06]
     After looking into this a bit, I think it is too much, I don't need it.
     The context manager part, I mean.
     [2025-05-06 Di 15:05]
     Also, sqlite3 connections only work in the thread that created them, so
     the whole concept of a Pool doesn't work.
*** Server [8/8]
    :PROPERTIES:
    :COOKIE_DATA: todo recursive
    :VISIBILITY: children
    :END:
    :LOGBOOK:
    CLOCK: [2025-04-24 Do 17:33]--[2025-04-24 Do 18:42] =>  1:09
    CLOCK: [2025-04-23 Mi 21:15]--[2025-04-23 Mi 21:40] =>  0:25
    CLOCK: [2025-04-23 Mi 17:45]--[2025-04-23 Mi 20:18] =>  2:33
    CLOCK: [2025-04-23 Mi 16:55]--[2025-04-23 Mi 16:59] =>  0:04
    CLOCK: [2025-04-22 Di 20:03]--[2025-04-23 Mi 00:39] =>  4:36
    :END:
**** Web Interface [2/3]
     :PROPERTIES:
     :COOKIE_DATA: todo recursive
     :VISIBILITY: children
     :END:
     :LOGBOOK:
     CLOCK: [2025-05-06 Di 18:55]--[2025-05-06 Di 23:18] =>  4:23
     CLOCK: [2025-05-06 Di 18:12]--[2025-05-06 Di 18:33] =>  0:21
     CLOCK: [2025-05-06 Di 15:06]--[2025-05-06 Di 15:31] =>  0:25
     CLOCK: [2025-05-06 Di 14:44]--[2025-05-06 Di 14:59] =>  0:15
     CLOCK: [2025-05-06 Di 10:16]--[2025-05-06 Di 10:24] =>  0:08
     CLOCK: [2025-05-05 Mo 21:02]--[2025-05-05 Mo 22:42] =>  1:40
     CLOCK: [2025-05-05 Mo 20:02]--[2025-05-05 Mo 20:34] =>  0:32
     :END:
     I am looking into Bottle first, which I have never used, but it sounds
     nice.
     For templating, I'll use [[https://jinja.palletsprojects.com/en/stable/][Jinja]].
     [2025-05-06 Di 18:12]
     *Update* So far both Bottle and Jinja2 are very pleasant to use.
     [2025-05-06 Di 23:18]
     *Update* For graphs, I will be using matplotlib, probably.
***** DONE Probe Graphs
      CLOSED: [2025-06-05 Do 19:26]
      :LOGBOOK:
      CLOCK: [2025-06-05 Do 17:00]--[2025-06-05 Do 19:25] =>  2:25
      CLOCK: [2025-06-04 Mi 16:15]--[2025-06-04 Mi 16:37] =>  0:22
      CLOCK: [2025-06-04 Mi 15:40]--[2025-06-04 Mi 16:00] =>  0:20
      CLOCK: [2025-06-04 Mi 09:13]--[2025-06-04 Mi 11:06] =>  1:53
      CLOCK: [2025-06-03 Di 18:02]--[2025-06-03 Di 20:35] =>  2:33
      CLOCK: [2025-06-03 Di 15:08]--[2025-06-03 Di 15:29] =>  0:21
      :END:
      In addition to the graphs on the Host detail pages, I want to render
      graphs that show the collected for a given probe across all registered
      hosts.
      [2025-06-03 Di 17:42]
      I just realized this is going to be slightly more complicated than I had
      expected, because I cannot expect for all Hosts to even have the same
      number of records for a given period, let alone that those records were
      collected at the same time.
      The way Pygal deals with time series is not very satisfactory anyway,
      maybe I should look into other options. ... Except I already did that,
      and it wasn't great, unless I am prepared to take the plunge and look
      into matplotlib again. Which I am *not* at this time, although I might
      do so in the future.
      ...
      /Hold that thought!/ - I just remembered I did one deadend project in Go
      where I ended up using a Javascript library for rendering the charts on
      the client side, and *that* did produce some rather nice
      charts.
***** TODO Graphs [1/1]
      :LOGBOOK:
      CLOCK: [2025-05-25 So 10:01]--[2025-05-25 So 21:26] => 11:25
      CLOCK: [2025-05-21 Mi 17:42]--[2025-05-21 Mi 20:45] =>  3:03
      CLOCK: [2025-05-20 Di 19:19]--[2025-05-20 Di 19:41] =>  0:22
      CLOCK: [2025-05-19 Mo 18:45]--[2025-05-19 Mo 20:34] =>  1:49
      CLOCK: [2025-05-17 Sa 20:55]--[2025-05-17 Sa 21:41] =>  0:46
      CLOCK: [2025-05-13 Di 19:31]--[2025-05-13 Di 19:55] =>  0:24
      CLOCK: [2025-05-08 Do 18:16]--[2025-05-08 Do 18:17] =>  0:01
      CLOCK: [2025-05-07 Mi 18:20]--[2025-05-07 Mi 19:21] =>  1:01
      CLOCK: [2025-05-07 Mi 17:21]--[2025-05-07 Mi 18:14] =>  0:53
      :END:
      In my first attempt, I will be using [[https://matplotlib.org/][Matplotlib]].
****** [2025-06-05 Do 19:32]
       Now that I render the Probe charts client side using chart.js, I wonder
       if I should use that for the host charts as well. 🤔
****** [2025-05-08 Do 18:16]
       Okay, so, whatever I want to, matplotlib is definitely up to the
       task. It is, however, hugely complex and almost certainly overkill for
       my simple needs.
       I shall therefore look at other options. The first I discovered is
       [[https://plotly.com/python/time-series/][Plotly]]. Let's see how that works out.
****** [2025-05-17 Sa 21:02]
       Okay, I do not get along with Maptplotlib, it is way too much. I'm
       going to look at alternatives, namely [[https://github.com/mingrammer/diagrams][diagrams]] and [[https://www.pygal.org/en/latest/][Pygal]].
****** [2025-05-17 Sa 21:42]
       I tried pygal first, and the first impression is great. I'm gonna try
       charting more probes and see how that goes.
****** [2025-05-19 Mo 18:46]
       Now that I can Agents to - kind of - automatically reconnect, I can
       focus on making pretty graphs, because that will involve restarting the
       server very often. /shrug/
****** DONE Labels on Y-axis
       CLOSED: [2025-05-27 Di 15:15]
       :LOGBOOK:
       CLOCK: [2025-05-27 Di 14:50]--[2025-05-27 Di 15:15] =>  0:25
       :END:
       I would like to format the labels on the Y-axis in a human-readable
       way, which would require different formatters for the different graphs.
**** DONE Error Handling [0/0]
     CLOSED: [2025-05-05 Mo 20:00]
     :PROPERTIES:
     :COOKIE_DATA: todo recursive
     :VISIBILITY: children
     :END:
     :LOGBOOK:
     CLOCK: [2025-05-05 Mo 18:01]--[2025-05-05 Mo 18:59] =>  0:58
     :END:
**** DONE Protocol
     CLOSED: [2025-06-02 Mo 18:41]
     :LOGBOOK:
     CLOCK: [2025-05-13 Di 17:10]--[2025-05-13 Di 17:43] =>  0:33
     CLOCK: [2025-05-03 Sa 21:40]--[2025-05-03 Sa 23:31] =>  1:51
     CLOCK: [2025-05-03 Sa 20:55]--[2025-05-03 Sa 21:33] =>  0:38
     CLOCK: [2025-05-02 Fr 21:22]--[2025-05-02 Fr 21:35] =>  0:13
     CLOCK: [2025-05-02 Fr 18:00]--[2025-05-02 Fr 19:00] =>  1:00
     CLOCK: [2025-05-02 Fr 16:21]--[2025-05-02 Fr 17:34] =>  1:13
     CLOCK: [2025-04-30 Mi 17:16]--[2025-04-30 Mi 22:58] =>  5:42
     CLOCK: [2025-04-29 Di 17:59]--[2025-04-29 Di 18:51] =>  0:52
     CLOCK: [2025-04-27 So 19:24]--[2025-04-27 So 21:34] =>  2:10
     :END:
     I think I should use TCP and model the agent-server-interaction using
     state machines. I've wanted to play with that anyway, so now I have an
     excuse.

     [2025-05-03 Sa 20:00]
     It doesn't work quite as I had intended. I think I need to look into
     asyncore or its successor.
     ...
     Oh my, asyncore doesn't exist any longer, asyncio seems a bit much.
***** DONE Handle Agent HTTP communication
      CLOSED: [2025-06-02 Mo 18:41]
      :LOGBOOK:
      CLOCK: [2025-06-02 Mo 17:52]--[2025-06-02 Mo 18:41] =>  0:49
      :END:
***** DONE In a pickle
      CLOSED: [2025-06-02 Mo 17:51]
      :LOGBOOK:
      CLOCK: [2025-05-23 Fr 09:55]--[2025-05-23 Fr 10:27] =>  0:32
      CLOCK: [2025-05-22 Do 18:08]--[2025-05-22 Do 19:27] =>  1:19
      :END:
**** SUSPENDED mDNS
     CLOSED: [2025-04-30 Mi 17:29]
     Every time, so far, I've dealt with mDNS, it either didn't work out, or
     the payoff was much, much lower than what I had hoped for.
     So for the time being, I'll shelve this idea.
*** Agent [2/2]
    :PROPERTIES:
    :COOKIE_DATA: todo recursive
    :VISIBILITY: children
    :END:
**** DONE HTTP FTW
     CLOSED: [2025-06-03 Di 14:58]
     :LOGBOOK:
     CLOCK: [2025-05-31 Sa 13:06]--[2025-05-31 Sa 20:03] =>  6:57
     CLOCK: [2025-05-30 Fr 16:58]--[2025-05-30 Fr 18:49] =>  1:51
     :END:
     I should switch the communication between Agent and Server to HTTP, the
     protocol I am using now is too error prone, and the Agent still tends to
     crash when connectivity is lost.
**** DONE Separate data collection and submission
     CLOSED: [2025-06-03 Di 14:58]
     I want to separate the collection of data from the probes from the
     submission of said data to the Server.
     That way I can deal with intermittent connectivity in a natural manner,
     and while I am switching to HTTP anyway, it makes sense to do it now.
** Refactor [0/0]
   :PROPERTIES:
   :COOKIE_DATA: todo recursive
   :VISIBILITY: children
   :END:
** Bugs [1/1]
   :PROPERTIES:
   :COOKIE_DATA: todo recursive
   :VISIBILITY: children
   :END:
   :LOGBOOK:
   CLOCK: [2025-05-12 Mo 17:50]--[2025-05-12 Mo 18:04] =>  0:14
   :END:
*** DONE Error deserializing report data
    CLOSED: [2025-05-30 Fr 16:52]
    :LOGBOOK:
    CLOCK: [2025-05-13 Di 18:15]--[2025-05-13 Di 18:53] =>  0:38
    :END:
    I get these strange errors when the Server is trying to deserialize report
    data from a client. Weirder still, the traceback says it comes from the
    *YAML* parser, which I don't even use, but apparently jsonpickle does
    (WTF???).
    I have a vague hunch this has something to do with the length of the
    message or the buffering of incoming data on the server.
    So I will first try to have the Agent deliver each Record individually.
    If that doesn't help, I might have to reconsider how I serialize data.
    Maybe I could use YAML directly, which I have not used in ... forever, but
    I have no particular reason not to use it.
    [2025-05-13 Di 18:53]
    Delivering the records individually appears to work (for now). The
    situation with YAML and the various libraries and their availability
    across different systems is just too much. So I'll leave it at this.
    [2025-05-22 Do 17:38]
    I am done with this crap, I'll just switch to plain pickle.
    I'll a fixed size field first that contains the length of the pickled
    data, followed by said data.
