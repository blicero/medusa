# -*- mode: org; fill-column: 78; -*-
# Time-stamp: <2025-05-25 21:27:12 krylon>
#
#+TAGS: internals(i) ui(u) bug(b) feature(f)
#+TAGS: database(d) design(e), meditation(m)
#+TAGS: optimize(o) refactor(r) cleanup(c)
#+TODO: TODO(t)  RESEARCH(r) IMPLEMENT(i) TEST(e) | DONE(d) FAILED(f) CANCELLED(c)
#+TODO: MEDITATE(m) PLANNING(p) | SUSPENDED(s)
#+PRIORITIES: A G D

* Medusa [8/13]
  :PROPERTIES:
  :COOKIE_DATA: todo recursive
  :VISIBILITY: children
  :END:
  An application to gather various metrics on hosts (e.g. CPU frequency,
  temperature, utilization, system load) and hopefully make pretty graphs out
  of that data.
** Clocktable
   #+BEGIN: clocktable :scope file :maxlevel 255 :emphasize t
   #+CAPTION: Clock summary at [2025-05-25 So 21:27]
   | Headline                              | Time      |            |         |         |       |
   |---------------------------------------+-----------+------------+---------+---------+-------|
   | *Total time*                          | *3d 2:08* |            |         |         |       |
   |---------------------------------------+-----------+------------+---------+---------+-------|
   | *Medusa [8/13]*                       | *3d 2:08* |            |         |         |       |
   | \_  /Features [1/1]/                  |           | /2:11/     |         |         |       |
   | \_    Intermittent connectivity [0/0] |           |            |    2:11 |         |       |
   | \_  /Components [7/11]/               |           | /2d 23:05/ |         |         |       |
   | \_    Main [0/0]                      |           |            |    0:40 |         |       |
   | \_    Probes [2/3]                    |           |            |   13:07 |         |       |
   | \_      Free disk space ?             |           |            |         |    1:47 |       |
   | \_      Conditional imports           |           |            |         |    1:09 |       |
   | \_      Sensors                       |           |            |         |    4:57 |       |
   | \_    Model [0/0]                     |           |            |    2:17 |         |       |
   | \_    Database [2/2]                  |           |            |    1:45 |         |       |
   | \_      Exception handling            |           |            |         |    0:09 |       |
   | \_      Pool                          |           |            |         |    0:28 |       |
   | \_    Server [3/6]                    |           |            | 2d 5:16 |         |       |
   | \_      Web Interface [0/1]           |           |            |         | 1d 3:28 |       |
   | \_        Graphs                      |           |            |         |         | 19:44 |
   | \_      Error Handling [0/0]          |           |            |         |    0:58 |       |
   | \_      Protocol                      |           |            |         |   16:03 |       |
   | \_        In a pickle                 |           |            |         |         |  1:51 |
   | \_  /Bugs [0/1]/                      |           | /0:52/     |         |         |       |
   | \_    Error deserializing report data |           |            |    0:38 |         |       |
   #+END:
** Features [1/1]
   :PROPERTIES:
   :COOKIE_DATA: todo recursive
   :VISIBILITY: children
   :END:
*** DONE Intermittent connectivity [0/0]
    CLOSED: [2025-05-19 Mo 17:57]
    :LOGBOOK:
    CLOCK: [2025-05-19 Mo 17:21]--[2025-05-19 Mo 17:57] =>  0:36
    CLOCK: [2025-05-18 So 17:52]--[2025-05-18 So 18:18] =>  0:26
    CLOCK: [2025-05-17 Sa 21:46]--[2025-05-17 Sa 22:55] =>  1:09
    :END:
    I need to handle loss of connection, on both sides. I am also unsure if I
    notice on the server side when an Agent connection is gone.
** Components [7/11]
   :PROPERTIES:
   :COOKIE_DATA: todo recursive
   :VISIBILITY: children
   :END:
*** Main [0/0]
    :LOGBOOK:
    CLOCK: [2025-05-07 Mi 19:23]--[2025-05-07 Mi 20:03] =>  0:40
    :END:
    The entry point, where it all begins.
*** Probes [2/3]
    :PROPERTIES:
    :COOKIE_DATA: todo recursive
    :VISIBILITY: children
    :END:
    :LOGBOOK:
    CLOCK: [2025-05-10 Sa 16:37]--[2025-05-10 Sa 18:37] =>  2:00
    CLOCK: [2025-05-10 Sa 15:50]--[2025-05-10 Sa 16:33] =>  0:43
    CLOCK: [2024-01-26 Fr 15:00]--[2024-01-26 Fr 16:39] =>  1:39
    CLOCK: [2024-01-25 Do 17:58]--[2024-01-25 Do 18:50] =>  0:52
    :END:
**** TODO Free disk space ?
     :LOGBOOK:
     CLOCK: [2025-05-13 Di 14:35]--[2025-05-13 Di 15:05] =>  0:30
     CLOCK: [2025-05-12 Mo 20:57]--[2025-05-12 Mo 22:14] =>  1:17
     :END:
**** DONE Conditional imports
     CLOSED: [2025-05-10 Sa 16:33]
     :LOGBOOK:
     CLOCK: [2025-05-09 Fr 17:20]--[2025-05-09 Fr 18:29] =>  1:09
     :END:
     I want to make the imports of the various probes conditional to keep the
     dependencies low.
     Also, I want to make the set of Probes an Agent runs configurable.
**** DONE Sensors
     CLOSED: [2025-05-20 Di 19:19]
     :LOGBOOK:
     CLOCK: [2025-05-20 Di 18:30]--[2025-05-20 Di 18:46] =>  0:16
     CLOCK: [2025-05-20 Di 14:41]--[2025-05-20 Di 15:26] =>  0:45
     CLOCK: [2025-05-19 Mo 20:34]--[2025-05-19 Mo 22:20] =>  1:46
     CLOCK: [2025-05-12 Mo 19:10]--[2025-05-12 Mo 20:57] =>  1:47
     CLOCK: [2025-05-12 Mo 18:12]--[2025-05-12 Mo 18:35] =>  0:23
     :END:
*** Model [0/0]
    :PROPERTIES:
    :COOKIE_DATA: todo recursive
    :VISIBILITY: children
    :END:
    :LOGBOOK:
    CLOCK: [2025-04-22 Di 18:17]--[2025-04-22 Di 18:51] =>  0:34
    CLOCK: [2025-04-21 Mo 13:31]--[2025-04-21 Mo 15:14] =>  1:43
    :END:
*** Database [2/2]
    :PROPERTIES:
    :COOKIE_DATA: todo recursive
    :VISIBILITY: children
    :END:
    :LOGBOOK:
    CLOCK: [2025-04-22 Di 18:51]--[2025-04-22 Di 19:04] =>  0:13
    CLOCK: [2025-04-22 Di 18:17]--[2025-04-22 Di 18:17] =>  0:00
    CLOCK: [2025-04-22 Di 14:23]--[2025-04-22 Di 15:18] =>  0:55
    :END:
**** DONE Exception handling
     CLOSED: [2025-05-05 Mo 17:57]
     :LOGBOOK:
     CLOCK: [2025-05-05 Mo 17:48]--[2025-05-05 Mo 17:57] =>  0:09
     :END:
**** DONE Pool
     CLOSED: [2025-04-29 Di 20:40]
     :LOGBOOK:
     CLOCK: [2025-04-24 Do 18:43]--[2025-04-24 Do 19:11] =>  0:28
     :END:
     I want a connection pool, similar to what I created in Go.
     And I want it to be a context manager, so I can say something like
     #+BEGIN_SRC Python
       with db_pool.get() as db:
           db.do_something(blah)
     #+END_SRC
     such that the the database instance will be returned to the pool on exit
     from the block.
     ...
     [2025-04-24 Do 19:06]
     After looking into this a bit, I think it is too much, I don't need it.
     The context manager part, I mean.
     [2025-05-06 Di 15:05]
     Also, sqlite3 connections only work in the thread that created them, so
     the whole concept of a Pool doesn't work.
*** Server [3/6]
    :PROPERTIES:
    :COOKIE_DATA: todo recursive
    :VISIBILITY: children
    :END:
    :LOGBOOK:
    CLOCK: [2025-04-24 Do 17:33]--[2025-04-24 Do 18:42] =>  1:09
    CLOCK: [2025-04-23 Mi 21:15]--[2025-04-23 Mi 21:40] =>  0:25
    CLOCK: [2025-04-23 Mi 17:45]--[2025-04-23 Mi 20:18] =>  2:33
    CLOCK: [2025-04-23 Mi 16:55]--[2025-04-23 Mi 16:59] =>  0:04
    CLOCK: [2025-04-22 Di 20:03]--[2025-04-23 Mi 00:39] =>  4:36
    :END:
**** TODO Web Interface [0/1]
     :PROPERTIES:
     :COOKIE_DATA: todo recursive
     :VISIBILITY: children
     :END:
     :LOGBOOK:
     CLOCK: [2025-05-06 Di 18:55]--[2025-05-06 Di 23:18] =>  4:23
     CLOCK: [2025-05-06 Di 18:12]--[2025-05-06 Di 18:33] =>  0:21
     CLOCK: [2025-05-06 Di 15:06]--[2025-05-06 Di 15:31] =>  0:25
     CLOCK: [2025-05-06 Di 14:44]--[2025-05-06 Di 14:59] =>  0:15
     CLOCK: [2025-05-06 Di 10:16]--[2025-05-06 Di 10:24] =>  0:08
     CLOCK: [2025-05-05 Mo 21:02]--[2025-05-05 Mo 22:42] =>  1:40
     CLOCK: [2025-05-05 Mo 20:02]--[2025-05-05 Mo 20:34] =>  0:32
     :END:
     I am looking into Bottle first, which I have never used, but it sounds
     nice.
     For templating, I'll use [[https://jinja.palletsprojects.com/en/stable/][Jinja]].
     [2025-05-06 Di 18:12]
     *Update* So far both Bottle and Jinja2 are very pleasant to use.
     [2025-05-06 Di 23:18]
     *Update* For graphs, I will be using matplotlib, probably.
***** TODO Graphs
      :LOGBOOK:
      CLOCK: [2025-05-25 So 10:01]--[2025-05-25 So 21:26] => 11:25
      CLOCK: [2025-05-21 Mi 17:42]--[2025-05-21 Mi 20:45] =>  3:03
      CLOCK: [2025-05-20 Di 19:19]--[2025-05-20 Di 19:41] =>  0:22
      CLOCK: [2025-05-19 Mo 18:45]--[2025-05-19 Mo 20:34] =>  1:49
      CLOCK: [2025-05-17 Sa 20:55]--[2025-05-17 Sa 21:41] =>  0:46
      CLOCK: [2025-05-13 Di 19:31]--[2025-05-13 Di 19:55] =>  0:24
      CLOCK: [2025-05-08 Do 18:16]--[2025-05-08 Do 18:17] =>  0:01
      CLOCK: [2025-05-07 Mi 18:20]--[2025-05-07 Mi 19:21] =>  1:01
      CLOCK: [2025-05-07 Mi 17:21]--[2025-05-07 Mi 18:14] =>  0:53
      :END:
      In my first attempt, I will be using [[https://matplotlib.org/][Matplotlib]].
****** [2025-05-08 Do 18:16]
       Okay, so, whatever I want to, matplotlib is definitely up to the
       task. It is, however, hugely complex and almost certainly overkill for
       my simple needs.
       I shall therefore look at other options. The first I discovered is
       [[https://plotly.com/python/time-series/][Plotly]]. Let's see how that works out.
****** [2025-05-17 Sa 21:02]
       Okay, I do not get along with Maptplotlib, it is way too much. I'm
       going to look at alternatives, namely [[https://github.com/mingrammer/diagrams][diagrams]] and [[https://www.pygal.org/en/latest/][Pygal]].
****** [2025-05-17 Sa 21:42]
       I tried pygal first, and the first impression is great. I'm gonna try
       charting more probes and see how that goes.
****** [2025-05-19 Mo 18:46]
       Now that I can Agents to - kind of - automatically reconnect, I can
       focus on making pretty graphs, because that will involve restarting the
       server very often. /shrug/
**** DONE Error Handling [0/0]
     CLOSED: [2025-05-05 Mo 20:00]
     :PROPERTIES:
     :COOKIE_DATA: todo recursive
     :VISIBILITY: children
     :END:
     :LOGBOOK:
     CLOCK: [2025-05-05 Mo 18:01]--[2025-05-05 Mo 18:59] =>  0:58
     :END:
**** DONE Protocol
     CLOSED: [2025-05-05 Mo 17:00]
     :LOGBOOK:
     CLOCK: [2025-05-13 Di 17:10]--[2025-05-13 Di 17:43] =>  0:33
     CLOCK: [2025-05-03 Sa 21:40]--[2025-05-03 Sa 23:31] =>  1:51
     CLOCK: [2025-05-03 Sa 20:55]--[2025-05-03 Sa 21:33] =>  0:38
     CLOCK: [2025-05-02 Fr 21:22]--[2025-05-02 Fr 21:35] =>  0:13
     CLOCK: [2025-05-02 Fr 18:00]--[2025-05-02 Fr 19:00] =>  1:00
     CLOCK: [2025-05-02 Fr 16:21]--[2025-05-02 Fr 17:34] =>  1:13
     CLOCK: [2025-04-30 Mi 17:16]--[2025-04-30 Mi 22:58] =>  5:42
     CLOCK: [2025-04-29 Di 17:59]--[2025-04-29 Di 18:51] =>  0:52
     CLOCK: [2025-04-27 So 19:24]--[2025-04-27 So 21:34] =>  2:10
     :END:
     I think I should use TCP and model the agent-server-interaction using
     state machines. I've wanted to play with that anyway, so now I have an
     excuse.

     [2025-05-03 Sa 20:00]
     It doesn't work quite as I had intended. I think I need to look into
     asyncore or its successor.
     ...
     Oh my, asyncore doesn't exist any longer, asyncio seems a bit much.
***** TODO In a pickle
      :LOGBOOK:
      CLOCK: [2025-05-23 Fr 09:55]--[2025-05-23 Fr 10:27] =>  0:32
      CLOCK: [2025-05-22 Do 18:08]--[2025-05-22 Do 19:27] =>  1:19
      :END:
**** SUSPENDED mDNS
     CLOSED: [2025-04-30 Mi 17:29]
     Every time, so far, I've dealt with mDNS, it either didn't work out, or
     the payoff was much, much lower than what I had hoped for.
     So for the time being, I'll shelve this idea.
*** Agent [0/0]
    :PROPERTIES:
    :COOKIE_DATA: todo recursive
    :VISIBILITY: children
    :END:
** Refactor [0/0]
   :PROPERTIES:
   :COOKIE_DATA: todo recursive
   :VISIBILITY: children
   :END:
** Bugs [0/1]
   :PROPERTIES:
   :COOKIE_DATA: todo recursive
   :VISIBILITY: children
   :END:
   :LOGBOOK:
   CLOCK: [2025-05-12 Mo 17:50]--[2025-05-12 Mo 18:04] =>  0:14
   :END:
*** TODO Error deserializing report data
    :LOGBOOK:
    CLOCK: [2025-05-13 Di 18:15]--[2025-05-13 Di 18:53] =>  0:38
    :END:
    I get these strange errors when the Server is trying to deserialize report
    data from a client. Weirder still, the traceback says it comes from the
    *YAML* parser, which I don't even use, but apparently jsonpickle does
    (WTF???).
    I have a vague hunch this has something to do with the length of the
    message or the buffering of incoming data on the server.
    So I will first try to have the Agent deliver each Record individually.
    If that doesn't help, I might have to reconsider how I serialize data.
    Maybe I could use YAML directly, which I have not used in ... forever, but
    I have no particular reason not to use it.
    [2025-05-13 Di 18:53]
    Delivering the records individually appears to work (for now). The
    situation with YAML and the various libraries and their availability
    across different systems is just too much. So I'll leave it at this.
    [2025-05-22 Do 17:38]
    I am done with this crap, I'll just switch to plain pickle.
    I'll a fixed size field first that contains the length of the pickled
    data, followed by said data.
